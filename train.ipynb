{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "kK_kaHeuFDWT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import csv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "K92fC4X6RMX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 128 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.0\n",
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kReuvuxIHGuh",
        "outputId": "fff27c62-47f2-4ccb-8898-07c71c80a7ec"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79fc98360870>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_TO_TOKEN = '#'\n",
        "AS_TOKEN = '$'\n",
        "END_TOKEN = '@'"
      ],
      "metadata": {
        "id": "7_QilntfVS2m"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "ILJ_bectRP1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA: dict[str, list[str]] = {\n",
        "    \"singular_to_plural\": [],\n",
        "    \"present_tense_to_past_tense\": [],\n",
        "    \"base_case_to_third_person_singular\": [],\n",
        "    \"singular_possessive_to_plural_possessive\": [],\n",
        "    \"comparative_adjective_to_superlative_adjective\": [],\n",
        "    \"verb_to_progressive_verb\": [],\n",
        "    \"verb_to_derived_agentive\": [],\n",
        "    \"base_case_to_diminuitive\": [],\n",
        "}\n",
        "\n",
        "TRAIN_DATA: dict[str, list[str]] = {\n",
        "    \"singular_to_plural\": [],\n",
        "    \"present_tense_to_past_tense\": [],\n",
        "    \"base_case_to_third_person_singular\": [],\n",
        "    \"singular_possessive_to_plural_possessive\": [],\n",
        "}\n",
        "\n",
        "VAL_DATA: dict[str, list[str]] = {\n",
        "    \"singular_to_plural\": [],\n",
        "    \"present_tense_to_past_tense\": [],\n",
        "    \"base_case_to_third_person_singular\": [],\n",
        "    \"singular_possessive_to_plural_possessive\": [],\n",
        "    \"comparative_adjective_to_superlative_adjective\": [],\n",
        "    \"verb_to_progressive_verb\": [],\n",
        "    \"verb_to_derived_agentive\": [],\n",
        "    \"base_case_to_diminuitive\": [],\n",
        "}"
      ],
      "metadata": {
        "id": "faIyPLhpHEfq"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ],
      "metadata": {
        "id": "qC-ELaw4RWsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_filepaths = [category + \".csv\" for category in DATA.keys()]\n",
        "for csv_filepath in csv_filepaths:\n",
        "  url = f\"https://raw.githubusercontent.com/adamoosya/182Proj/main/data/{csv_filepath}\"\n",
        "  !wget --no-cache --backups=1 {url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bGUd3rqbRZjw",
        "outputId": "1de73d86-f2cd-4f3d-a39a-5457b780e9b0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-23 02:32:00--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/singular_to_plural.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147270 (144K) [text/plain]\n",
            "Saving to: ‘singular_to_plural.csv’\n",
            "\n",
            "singular_to_plural. 100%[===================>] 143.82K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-04-23 02:32:01 (51.8 MB/s) - ‘singular_to_plural.csv’ saved [147270/147270]\n",
            "\n",
            "--2025-04-23 02:32:01--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/present_tense_to_past_tense.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137318 (134K) [text/plain]\n",
            "Saving to: ‘present_tense_to_past_tense.csv’\n",
            "\n",
            "present_tense_to_pa 100%[===================>] 134.10K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-04-23 02:32:01 (61.6 MB/s) - ‘present_tense_to_past_tense.csv’ saved [137318/137318]\n",
            "\n",
            "--2025-04-23 02:32:01--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/base_case_to_third_person_singular.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 151549 (148K) [text/plain]\n",
            "Saving to: ‘base_case_to_third_person_singular.csv’\n",
            "\n",
            "base_case_to_third_ 100%[===================>] 148.00K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-04-23 02:32:02 (73.9 MB/s) - ‘base_case_to_third_person_singular.csv’ saved [151549/151549]\n",
            "\n",
            "--2025-04-23 02:32:02--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/singular_possessive_to_plural_possessive.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 186327 (182K) [text/plain]\n",
            "Saving to: ‘singular_possessive_to_plural_possessive.csv’\n",
            "\n",
            "singular_possessive 100%[===================>] 181.96K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-04-23 02:32:02 (55.6 MB/s) - ‘singular_possessive_to_plural_possessive.csv’ saved [186327/186327]\n",
            "\n",
            "--2025-04-23 02:32:02--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/comparative_adjective_to_superlative_adjective.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184493 (180K) [text/plain]\n",
            "Saving to: ‘comparative_adjective_to_superlative_adjective.csv’\n",
            "\n",
            "comparative_adjecti 100%[===================>] 180.17K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-04-23 02:32:02 (59.8 MB/s) - ‘comparative_adjective_to_superlative_adjective.csv’ saved [184493/184493]\n",
            "\n",
            "--2025-04-23 02:32:03--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/verb_to_progressive_verb.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 174339 (170K) [text/plain]\n",
            "Saving to: ‘verb_to_progressive_verb.csv’\n",
            "\n",
            "verb_to_progressive 100%[===================>] 170.25K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-04-23 02:32:03 (53.6 MB/s) - ‘verb_to_progressive_verb.csv’ saved [174339/174339]\n",
            "\n",
            "--2025-04-23 02:32:03--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/verb_to_derived_agentive.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173666 (170K) [text/plain]\n",
            "Saving to: ‘verb_to_derived_agentive.csv’\n",
            "\n",
            "verb_to_derived_age 100%[===================>] 169.60K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-04-23 02:32:03 (40.8 MB/s) - ‘verb_to_derived_agentive.csv’ saved [173666/173666]\n",
            "\n",
            "--2025-04-23 02:32:03--  https://raw.githubusercontent.com/adamoosya/182Proj/main/data/base_case_to_diminuitive.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101108 (99K) [text/plain]\n",
            "Saving to: ‘base_case_to_diminuitive.csv’\n",
            "\n",
            "base_case_to_diminu 100%[===================>]  98.74K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-04-23 02:32:04 (48.2 MB/s) - ‘base_case_to_diminuitive.csv’ saved [101108/101108]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for category in DATA.keys():\n",
        "  csv_filepath = category + \".csv\"\n",
        "  with open(csv_filepath, 'r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    word_pairs = set()\n",
        "    for row in reader:\n",
        "      if len(row) >= 2:  # Ensure there are at least two elements in the row\n",
        "        word1, word2 = row[0], row[1]\n",
        "        if all(c in stoi for c in word1) and all(c in stoi for c in word2):\n",
        "          word_pairs.add((word1, word2))\n",
        "    word_pairs = list(word_pairs)\n",
        "    DATA[category] = word_pairs"
      ],
      "metadata": {
        "id": "FmHAVgVnSuP7"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_categories = [\"singular_to_plural\", \"present_tense_to_past_tense\", \"base_case_to_third_person_singular\", \"singular_possessive_to_plural_possessive\"]\n",
        "\n",
        "for category, word_pairs in DATA.items():\n",
        "  if category in train_categories:\n",
        "    split_index = int(0.9 * len(word_pairs))\n",
        "    TRAIN_DATA[category] = word_pairs[:split_index]\n",
        "    VAL_DATA[category] = word_pairs[split_index:]\n",
        "  else:\n",
        "    VAL_DATA[category] = word_pairs"
      ],
      "metadata": {
        "id": "ZiGzTpLZT5Aq"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category, word_pairs in DATA.items():\n",
        "  print(f\"{category}: {len(word_pairs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byh_epqTUv2Q",
        "outputId": "07ab163f-fed3-45ed-e2be-b78477d139b7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "singular_to_plural: 878\n",
            "present_tense_to_past_tense: 618\n",
            "base_case_to_third_person_singular: 674\n",
            "singular_possessive_to_plural_possessive: 969\n",
            "comparative_adjective_to_superlative_adjective: 1096\n",
            "verb_to_progressive_verb: 640\n",
            "verb_to_derived_agentive: 887\n",
            "base_case_to_diminuitive: 2170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {\n",
        "    ' ': 0,\n",
        "    'a': 1,\n",
        "    'b': 2,\n",
        "    'c': 3,\n",
        "    'd': 4,\n",
        "    'e': 5,\n",
        "    'f': 6,\n",
        "    'g': 7,\n",
        "    'h': 8,\n",
        "    'i': 9,\n",
        "    'j': 10,\n",
        "    'k': 11,\n",
        "    'l': 12,\n",
        "    'm': 13,\n",
        "    'n': 14,\n",
        "    'o': 15,\n",
        "    'p': 16,\n",
        "    'q': 17,\n",
        "    'r': 18,\n",
        "    's': 19,\n",
        "    't': 20,\n",
        "    'u': 21,\n",
        "    'v': 22,\n",
        "    'w': 23,\n",
        "    'x': 24,\n",
        "    'y': 25,\n",
        "    'z': 26,\n",
        "    '#': 27,\n",
        "    '$': 28,\n",
        "    '@': 29,\n",
        "    '\\'': 30\n",
        "}\n",
        "# '# = is to'\n",
        "# '$ = as'\n",
        "# '@ = end token'\n",
        "# '% = padding at the end to make it block size length'\n",
        "vocab_size = len(stoi)\n",
        "\n",
        "itos = {v: k for k, v in stoi.items()}\n",
        "\n",
        "# def tokenize(text):\n",
        "#     return [CHAR_TO_TOKEN[c] for c in text]\n",
        "\n",
        "# def detokenize(tokens):\n",
        "#     return ''.join([TOKEN_TO_CHAR[t] for t in tokens])\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
      ],
      "metadata": {
        "id": "OjsDegqUWbfN"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_context_test(dataset, category=None):\n",
        "    '''\n",
        "    For example:\n",
        "    context = fox$foxes#dog$\n",
        "    target = dogs\n",
        "    '''\n",
        "    if category is None:\n",
        "        category = np.random.choice(list(dataset.keys()))\n",
        "    data = dataset[category]\n",
        "    n = len(data)\n",
        "    s1, p1 = data[np.random.randint(n)]\n",
        "    s2, p2 = data[np.random.randint(n)]\n",
        "    context = s1 + IS_TO_TOKEN + p1 + AS_TOKEN + s2 + IS_TO_TOKEN\n",
        "    target = s2\n",
        "    return context, target\n",
        "\n",
        "def get_context_example(dataset, category=None):\n",
        "    '''\n",
        "    Data is of the form:\n",
        "    singular $ plural # singular $ part of a plural\n",
        "\n",
        "    For example:\n",
        "    x = fox$foxes#dog$do\n",
        "    y = ox$foxes#dog$dog\n",
        "    '''\n",
        "    if category is None:\n",
        "        category = np.random.choice(list(dataset.keys()))\n",
        "    data = dataset[category]\n",
        "    n = len(data)\n",
        "    s1, p1 = data[np.random.randint(n)]\n",
        "    s2, p2 = data[np.random.randint(n)]\n",
        "    window = np.random.randint(len(p2)+1)\n",
        "    p2 += END_TOKEN\n",
        "    x = s1 + IS_TO_TOKEN + p1 + AS_TOKEN + s2 + IS_TO_TOKEN + p2[:window]\n",
        "    y = s1[1:] + IS_TO_TOKEN + p1 + AS_TOKEN + s2 + IS_TO_TOKEN + p2[:window + 1]\n",
        "    x = torch.tensor(encode(x))\n",
        "    y = torch.tensor(encode(y))\n",
        "    return x, y\n",
        "\n",
        "def get_batch(dataset, category=None, batch_size=batch_size):\n",
        "    x = torch.zeros((batch_size, block_size), dtype=int)\n",
        "    y = torch.zeros((batch_size, block_size), dtype=int)\n",
        "    mask = torch.zeros((batch_size, block_size), dtype=torch.bool)\n",
        "    for i in range(batch_size):\n",
        "        xi, yi = get_context_example(dataset, category=category)\n",
        "        x[i, :len(xi)] = xi  # Assign values up to the original length\n",
        "        y[i, :len(yi)] = yi  # The rest will be padded with 0s\n",
        "        mask[i, :len(xi)] = True  # Set True for actual data tokens\n",
        "\n",
        "    x, y, mask = x.to(device), y.to(device), mask.to(device)\n",
        "    return x, y, mask"
      ],
      "metadata": {
        "id": "m90TjetiVIF5"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = get_context_example(TRAIN_DATA)\n",
        "print(decode(example[0].tolist()))\n",
        "print(decode(example[1].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-226G_yBXq5U",
        "outputId": "f8b548ef-4de4-4537-b6f5-1b729823165c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mixer#mixers$gymnasium#gymnasi\n",
            "ixer#mixers$gymnasium#gymnasiu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss(model, dataset, category=None):\n",
        "    model.eval()\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "        X, Y, mask = get_batch(dataset, category=category)\n",
        "        logits, loss = model(X, Y, mask)\n",
        "        losses[k] = loss.item()\n",
        "    out = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        if mask is not None:\n",
        "            # Apply the mask before the softmax\n",
        "            wei = wei.masked_fill(~mask[:, None, :], float('-inf'))\n",
        "\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        #out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = torch.cat([h(x, mask=mask) for h in self.heads], dim=-1)  # Pass mask\n",
        "\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = x + self.sa(self.ln1(x), mask=mask)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None, mask=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        for block in self.blocks:\n",
        "          x = block(x, mask=mask)\n",
        "\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def test(self, context, target):\n",
        "        model.eval()\n",
        "        idx = torch.tensor(encode(context)).to(device).unsqueeze(0)\n",
        "        t = len(target)\n",
        "        for i in range(t):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "\n",
        "        prediction = decode(idx[0].tolist())[-t:]\n",
        "        model.train()\n",
        "        return prediction == target"
      ],
      "metadata": {
        "id": "xuMYquuvX9vw"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataset, category=None, num_to_evaluate=100):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for _ in range(num_to_evaluate):\n",
        "        context, target = get_context_test(dataset, category=category)\n",
        "        if model.test(context, target):\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "dxouv68vcEOl"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTLanguageModel()\n",
        "model = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = {\n",
        "    'train': {\n",
        "        'singular_to_plural': [],\n",
        "        'present_tense_to_past_tense': [],\n",
        "        'base_case_to_third_person_singular': [],\n",
        "        'singular_possessive_to_plural_possessive': [],\n",
        "    },\n",
        "    'val': {\n",
        "        \"singular_to_plural\": [],\n",
        "        \"present_tense_to_past_tense\": [],\n",
        "        \"base_case_to_third_person_singular\": [],\n",
        "        \"singular_possessive_to_plural_possessive\": [],\n",
        "        \"comparative_adjective_to_superlative_adjective\": [],\n",
        "        \"verb_to_progressive_verb\": [],\n",
        "        \"verb_to_derived_agentive\": [],\n",
        "        \"base_case_to_diminuitive\": [],\n",
        "    }\n",
        "}\n",
        "correctness = {\n",
        "    'train': {\n",
        "        'singular_to_plural': [],\n",
        "        'present_tense_to_past_tense': [],\n",
        "        'base_case_to_third_person_singular': [],\n",
        "        'singular_possessive_to_plural_possessive': [],\n",
        "    },\n",
        "    'val': {\n",
        "        \"singular_to_plural\": [],\n",
        "        \"present_tense_to_past_tense\": [],\n",
        "        \"base_case_to_third_person_singular\": [],\n",
        "        \"singular_possessive_to_plural_possessive\": [],\n",
        "        \"comparative_adjective_to_superlative_adjective\": [],\n",
        "        \"verb_to_progressive_verb\": [],\n",
        "        \"verb_to_derived_agentive\": [],\n",
        "        \"base_case_to_diminuitive\": [],\n",
        "    }\n",
        "}\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        for dataset, dataset_name in zip([TRAIN_DATA, VAL_DATA], ['train', 'val']):\n",
        "          loss = estimate_loss(model, dataset, category=None)\n",
        "          print(f\"{iter}: {dataset_name}: {loss.item():.4f}\")\n",
        "          score = evaluate(model, dataset, category=None)\n",
        "          print(f\"{iter}: {dataset_name}: {score:.4f}\")\n",
        "\n",
        "        # for dataset, dataset_name in zip([TRAIN_DATA, VAL_DATA], ['train', 'val']):\n",
        "        #     for category in dataset.keys():\n",
        "        #         loss = estimate_loss(model, dataset, category=category)\n",
        "        #         print(f\"{iter}: {dataset_name} {category}: {loss.item():.4f}\")\n",
        "        #         losses[dataset_name][category].append(loss)\n",
        "\n",
        "        #         score = evaluate(model, dataset, category=category)\n",
        "        #         correctness[dataset_name][category].append(score)\n",
        "        #         print(f\"{iter}: {dataset_name} {category}: {score:.4f}\")\n",
        "        #losses = estimate_loss()\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb, mask = get_batch(TRAIN_DATA)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb, mask)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh3kRt1LY7Vh",
        "outputId": "339dafb0-143b-4fe3-80dd-cc7993afdaf5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.713631 M parameters\n",
            "0: train: 3.3023\n",
            "0: train: 0.0000\n",
            "0: val: 3.2857\n",
            "0: val: 0.0000\n",
            "500: train: 0.1711\n",
            "500: train: 0.6100\n",
            "500: val: 0.3443\n",
            "500: val: 0.5800\n",
            "1000: train: 0.1192\n",
            "1000: train: 0.5400\n",
            "1000: val: 0.3741\n",
            "1000: val: 0.6500\n",
            "1500: train: 0.1136\n",
            "1500: train: 0.6400\n",
            "1500: val: 0.3862\n",
            "1500: val: 0.6600\n",
            "2000: train: 0.1052\n",
            "2000: train: 0.6400\n",
            "2000: val: 0.4131\n",
            "2000: val: 0.6300\n",
            "2500: train: 0.1039\n",
            "2500: train: 0.6300\n",
            "2500: val: 0.4166\n",
            "2500: val: 0.6200\n",
            "3000: train: 0.1035\n",
            "3000: train: 0.6500\n",
            "3000: val: 0.4311\n",
            "3000: val: 0.6000\n",
            "3500: train: 0.1028\n",
            "3500: train: 0.6200\n",
            "3500: val: 0.4341\n",
            "3500: val: 0.6300\n",
            "4000: train: 0.1005\n",
            "4000: train: 0.6300\n",
            "4000: val: 0.4465\n",
            "4000: val: 0.7900\n",
            "4500: train: 0.1000\n",
            "4500: train: 0.5900\n",
            "4500: val: 0.4459\n",
            "4500: val: 0.6600\n",
            "4999: train: 0.1009\n",
            "4999: train: 0.5000\n",
            "4999: val: 0.4418\n",
            "4999: val: 0.5900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'train_weights.pth')"
      ],
      "metadata": {
        "id": "uocsGxupjHDV"
      },
      "execution_count": 85,
      "outputs": []
    }
  ]
}